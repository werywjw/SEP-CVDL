{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: mps\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn import Linear, Conv2d, BatchNorm1d, BatchNorm2d, PReLU, Sequential, Module\n",
    "from torchvision.transforms import transforms\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from matplotlib import pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch.optim as optim\n",
    "from tqdm import tqdm\n",
    "from sklearn.model_selection import ParameterGrid\n",
    "\n",
    "device = torch.device(\"mps\" if torch.backends.mps.is_available() else \"cpu\")\n",
    "# device = torch.device(\"cpu\")\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os\n",
    "# import pandas as pd\n",
    "# from PIL import Image\n",
    "# from torch.utils.data import Dataset\n",
    "# import torch\n",
    "\n",
    "# class RAFDBDataset(Dataset):\n",
    "#     def __init__(self, csv_file, img_dir, transform=None):\n",
    "#         self.labels = pd.read_csv(csv_file)\n",
    "#         self.img_dir = img_dir\n",
    "#         self.transform = transform\n",
    "\n",
    "#     def __len__(self):\n",
    "#         return len(self.labels)\n",
    "\n",
    "#     def __getitem__(self, idx):\n",
    "#         if torch.is_tensor(idx):\n",
    "#             idx = idx.tolist()\n",
    "\n",
    "#         img_name = os.path.join(self.img_dir, self.labels.iloc[idx, 0])\n",
    "#         image = Image.open(img_name)\n",
    "#         label = self.labels.iloc[idx, 1]\n",
    "#         if self.transform:\n",
    "#             image = self.transform(image)\n",
    "\n",
    "#         return image, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train batch: image shape torch.Size([16, 3, 64, 64]), labels shape torch.Size([16])\n",
      "Vali batch: image shape torch.Size([16, 3, 64, 64]), labels shape torch.Size([16])\n",
      "Test batch: image shape torch.Size([16, 3, 64, 64]), labels shape torch.Size([16])\n"
     ]
    }
   ],
   "source": [
    "from get_dataset import GiMeFiveDataset\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((64, 64)),\n",
    "    transforms.Grayscale(num_output_channels=3),\n",
    "    transforms.RandomHorizontalFlip(), \n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "    # transforms.RandomErasing(scale=(0.02,0.25)),\n",
    "])\n",
    "    \n",
    "rafdb_dataset_train = GiMeFiveDataset(csv_file='archive/RAF-DB/train_RAF_labels.csv',\n",
    "                            img_dir='archive/RAF-DB/train/',\n",
    "                            transform=transform)\n",
    "\n",
    "# rafdb_dataset_train = GiMeFiveDataset(csv_file='archive/FER2013/train_FER_labels.csv',\n",
    "#                             img_dir='archive/FER2013/train/',\n",
    "#                             transform=transform)\n",
    "\n",
    "# rafdb_dataset_train = GiMeFiveDataset(csv_file='data/train_labels.csv',\n",
    "#                             img_dir='data/train/',\n",
    "#                             transform=transform)\n",
    "data_train_loader = DataLoader(rafdb_dataset_train, batch_size=16, shuffle=True, num_workers=4)\n",
    "train_image, train_label = next(iter(data_train_loader))\n",
    "print(f\"Train batch: image shape {train_image.shape}, labels shape {train_label.shape}\")\n",
    "\n",
    "rafdb_dataset_vali = GiMeFiveDataset(csv_file='data/valid_labels.csv',\n",
    "                            img_dir='data/valid',\n",
    "                            transform=transform)\n",
    "data_vali_loader = DataLoader(rafdb_dataset_vali, batch_size=16, shuffle=False, num_workers=0)\n",
    "vali_image, vali_label = next(iter(data_vali_loader))\n",
    "print(f\"Vali batch: image shape {vali_image.shape}, labels shape {vali_label.shape}\")\n",
    "\n",
    "rafdb_dataset_test = GiMeFiveDataset(csv_file='archive/RAF-DB/test_RAF_labels.csv',\n",
    "                            img_dir='archive/RAF-DB/test/',\n",
    "                            transform=transform)\n",
    "\n",
    "# rafdb_dataset_test = GiMeFiveDataset(csv_file='archive/FER2013/test_FER_labels.csv',\n",
    "#                             img_dir='archive/FER2013/test/',\n",
    "#                             transform=transform)\n",
    "\n",
    "# rafdb_dataset_test = GiMeFiveDataset(csv_file='data/test_labels.csv',\n",
    "#                             img_dir='data/test/',\n",
    "#                             transform=transform)\n",
    "data_test_loader = DataLoader(rafdb_dataset_test, batch_size=16, shuffle=False, num_workers=0)\n",
    "test_image, test_label = next(iter(data_test_loader))\n",
    "print(f\"Test batch: image shape {test_image.shape}, labels shape {test_label.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SEBlock(nn.Module): # Squeeze-and-Excitation (SE) blocks apply channel-wise attention.\n",
    "    def __init__(self, input_channels, reduction=16):\n",
    "        super(SEBlock, self).__init__()\n",
    "        self.avg_pool = nn.AdaptiveAvgPool2d(1)\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(input_channels, input_channels // reduction, bias=False),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(input_channels // reduction, input_channels, bias=False),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        b, c, _, _ = x.size()\n",
    "        y = self.avg_pool(x).view(b, c)\n",
    "        y = self.fc(y).view(b, c, 1, 1)\n",
    "        return x * y.expand_as(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResidualBlock(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, stride=1):\n",
    "        super(ResidualBlock, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels, out_channels, kernel_size=3, stride=stride, padding=1)\n",
    "        self.bn1 = nn.BatchNorm2d(out_channels)\n",
    "        self.conv2 = nn.Conv2d(out_channels, out_channels, kernel_size=3, stride=1, padding=1)\n",
    "        self.bn2 = nn.BatchNorm2d(out_channels)\n",
    "\n",
    "        self.shortcut = nn.Sequential()\n",
    "        if stride != 1 or in_channels != out_channels:\n",
    "            self.shortcut = nn.Sequential(\n",
    "                nn.Conv2d(in_channels, out_channels, kernel_size=1, stride=stride, padding=0),\n",
    "                nn.BatchNorm2d(out_channels)\n",
    "            )\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = F.relu(self.bn1(self.conv1(x)))\n",
    "        out = self.bn2(self.conv2(out))\n",
    "        out += self.shortcut(x)  \n",
    "        out = F.relu(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# class EmotionClassifier(nn.Module):\n",
    "#     def __init__(self):\n",
    "#         super(EmotionClassifier, self).__init__()\n",
    "#         self.conv1 = nn.Conv2d(3, 64, kernel_size=3, padding=1)\n",
    "#         self.bn1 = nn.BatchNorm2d(64)\n",
    "#         self.relu = nn.ReLU(inplace=True)\n",
    "#         self.se1 = SEBlock(64)\n",
    "\n",
    "#         self.res_block1 = ResidualBlock(64, 128, stride=2)\n",
    "#         self.res_block2 = ResidualBlock(128, 256, stride=2)\n",
    "#         self.res_block3 = ResidualBlock(256, 512, stride=2)\n",
    "#         self.res_block4 = ResidualBlock(512, 1024, stride=2)\n",
    "#         self.res_block5 = ResidualBlock(1024, 2048, stride=2)\n",
    "\n",
    "#         self.pool = nn.AdaptiveAvgPool2d((1, 1))\n",
    "#         self.fc1 = nn.Linear(2048, 4096)\n",
    "#         self.fc2 = nn.Linear(4096, 2048) \n",
    "#         self.dropout1 = nn.Dropout(0.5)\n",
    "#         self.fc3 = nn.Linear(2048, 6)\n",
    "\n",
    "#     def forward(self, x):\n",
    "#         x = self.relu(self.bn1(self.conv1(x)))\n",
    "#         x = self.se1(x)\n",
    "        \n",
    "#         x = self.res_block1(x)\n",
    "#         x = self.res_block2(x)\n",
    "#         x = self.res_block3(x)\n",
    "#         x = self.res_block4(x)\n",
    "#         x = self.res_block5(x)\n",
    "        \n",
    "#         x = self.pool(x)\n",
    "#         x = x.view(x.size(0), -1)\n",
    "#         x = F.relu(self.fc1(x))\n",
    "#         x = self.dropout1(x)\n",
    "#         x = F.relu(self.fc2(x))\n",
    "#         x = self.fc3(x)\n",
    "#         return x\n",
    "    \n",
    "# model = EmotionClassifier().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EmotionClassifier(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(EmotionClassifier, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 64, kernel_size=3, padding=1)\n",
    "        self.bn1 = nn.BatchNorm2d(64)\n",
    "        self.conv2 = nn.Conv2d(64, 128, kernel_size=3, padding=1)\n",
    "        self.bn2 = nn.BatchNorm2d(128)\n",
    "        self.conv3 = nn.Conv2d(128, 256, kernel_size=3, padding=1)\n",
    "        self.bn3 = nn.BatchNorm2d(256)\n",
    "        self.conv4 = nn.Conv2d(256, 512, kernel_size=3, padding=1)\n",
    "        self.bn4 = nn.BatchNorm2d(512)\n",
    "        self.conv5 = nn.Conv2d(512, 1024, kernel_size=3, padding=1)\n",
    "        self.bn5 = nn.BatchNorm2d(1024)\n",
    "\n",
    "        self.pool = nn.AdaptiveAvgPool2d((1, 1))\n",
    "        self.fc1 = nn.Linear(1024, 2048)\n",
    "        self.fc2 = nn.Linear(2048, 1024) \n",
    "        self.dropout1 = nn.Dropout(0.2)\n",
    "        self.dropout2 = nn.Dropout(0.5)\n",
    "        self.fc3 = nn.Linear(1024, 6)\n",
    "\n",
    "    def forward(self, x): # (batch_size, channels=3, 64, 64)\n",
    "        x = F.relu(self.bn1(self.conv1(x))) # (batch_size, 64, 64, 64)\n",
    "        x = F.max_pool2d(x, 2) # (batch_size, 64, 32, 32)\n",
    "        x = self.dropout1(x)\n",
    "        x = F.relu(self.bn2(self.conv2(x))) # (batch_size, 128, 32, 32)\n",
    "        x = F.max_pool2d(x, 2) # (batch_size, 128, 16, 16)\n",
    "        x = self.dropout1(x)\n",
    "        x = F.relu(self.bn3(self.conv3(x))) # (batch_size, 256, 16, 16)\n",
    "        x = F.max_pool2d(x, 2) # (batch_size, 256, 8, 8)\n",
    "        x = self.dropout1(x)\n",
    "        x = F.relu(self.bn4(self.conv4(x))) # (batch_size, 512, 8, 8)\n",
    "        x = F.max_pool2d(x, 2) # (batch_size, 512, 4, 4)\n",
    "        x = self.dropout1(x)\n",
    "        x = F.relu(self.bn5(self.conv5(x))) # (batch_size, 1024, 4, 4)\n",
    "        x = F.max_pool2d(x, 2) # (batch_size, 1024, 2, 2)\n",
    "        # x = self.dropout1(x)\n",
    "        \n",
    "        x = self.pool(x) # (batch_size, 1024, 1, 1)\n",
    "        x = x.view(x.size(0), -1) # (batch_size, 1024) # Flatten\n",
    "        x = F.relu(self.fc1(x)) # (batch_size, 2048)\n",
    "        x = self.dropout2(x) # (batch_size, 2048)\n",
    "        x = F.relu(self.fc2(x)) # (batch_size, 1024)\n",
    "        x = self.fc3(x) # (batch_size, 6)\n",
    "        return x\n",
    "\n",
    "model = EmotionClassifier().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.load_state_dict(torch.load('best_baseline.pth', map_location=device))\n",
    "# model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Baseline(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Baseline, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 64, kernel_size=3, padding=1)\n",
    "        self.bn1 = nn.BatchNorm2d(64)\n",
    "        self.conv2 = nn.Conv2d(64, 128, kernel_size=3, padding=1)\n",
    "        self.bn2 = nn.BatchNorm2d(128)\n",
    "        self.conv3 = nn.Conv2d(128, 256, kernel_size=3, padding=1)\n",
    "        self.bn3 = nn.BatchNorm2d(256)\n",
    "        self.conv4 = nn.Conv2d(256, 512, kernel_size=3, padding=1)\n",
    "        self.bn4 = nn.BatchNorm2d(512)\n",
    "        # self.conv5 = nn.Conv2d(512, 1024, kernel_size=3, padding=1)\n",
    "        # self.bn5 = nn.BatchNorm2d(1024)\n",
    "\n",
    "        self.pool = nn.AdaptiveAvgPool2d((1, 1))\n",
    "        self.fc1 = nn.Linear(512, 1024)\n",
    "        self.fc2 = nn.Linear(1024, 512) \n",
    "        self.dropout1 = nn.Dropout(0.2)\n",
    "        self.dropout2 = nn.Dropout(0.5)\n",
    "        self.fc3 = nn.Linear(512, 6)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.bn1(self.conv1(x))) \n",
    "        x = F.max_pool2d(x, 2) \n",
    "        x = self.dropout1(x)\n",
    "        x = F.relu(self.bn2(self.conv2(x)))\n",
    "        x = F.max_pool2d(x, 2)\n",
    "        x = self.dropout1(x)\n",
    "        x = F.relu(self.bn3(self.conv3(x)))\n",
    "        x = F.max_pool2d(x, 2) \n",
    "        x = self.dropout1(x)\n",
    "        x = F.relu(self.bn4(self.conv4(x))) \n",
    "        x = F.max_pool2d(x, 2) \n",
    "        x = self.dropout1(x)\n",
    "        # x = F.relu(self.bn5(self.conv5(x))) \n",
    "        # x = F.max_pool2d(x, 2)\n",
    "        # x = self.dropout1(x)\n",
    "        \n",
    "        x = self.pool(x) \n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = F.relu(self.fc1(x)) \n",
    "        x = self.dropout2(x) \n",
    "        x = F.relu(self.fc2(x)) \n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "    \n",
    "model = Baseline().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total trainable parameters: 2606086\n"
     ]
    }
   ],
   "source": [
    "total_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "print(f\"Total trainable parameters: {total_params}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import torch\n",
    "# import torch.nn as nn\n",
    "# import torch.nn.functional as F\n",
    "\n",
    "# class BasicBlock(nn.Module):\n",
    "#     expansion = 1\n",
    "\n",
    "#     def __init__(self, in_planes, planes, stride=1):\n",
    "#         super(BasicBlock, self).__init__()\n",
    "#         self.conv1 = nn.Conv2d(in_planes, planes, kernel_size=3, stride=stride, padding=1, bias=False)\n",
    "#         self.bn1 = nn.BatchNorm2d(planes)\n",
    "#         self.conv2 = nn.Conv2d(planes, planes, kernel_size=3, stride=1, padding=1, bias=False)\n",
    "#         self.bn2 = nn.BatchNorm2d(planes)\n",
    "\n",
    "#         self.shortcut = nn.Sequential()\n",
    "#         if stride != 1 or in_planes != self.expansion * planes:\n",
    "#             self.shortcut = nn.Sequential(\n",
    "#                 nn.Conv2d(in_planes, self.expansion * planes, kernel_size=1, stride=stride, bias=False),\n",
    "#                 nn.BatchNorm2d(self.expansion * planes)\n",
    "#             )\n",
    "\n",
    "#     def forward(self, x):\n",
    "#         out = F.relu(self.bn1(self.conv1(x)))\n",
    "#         out = self.bn2(self.conv2(out))\n",
    "#         out += self.shortcut(x)\n",
    "#         out = F.relu(out)\n",
    "#         return out\n",
    "\n",
    "# class ResNet(nn.Module):\n",
    "#     def __init__(self, block, num_blocks, num_classes=6):\n",
    "#         super(ResNet, self).__init__()\n",
    "#         self.in_planes = 64\n",
    "\n",
    "#         self.conv1 = nn.Conv2d(3, 64, kernel_size=7, stride=2, padding=3, bias=False)\n",
    "#         self.bn1 = nn.BatchNorm2d(64)\n",
    "#         self.layer1 = self._make_layer(block, 64, num_blocks[0], stride=1)\n",
    "#         self.layer2 = self._make_layer(block, 128, num_blocks[1], stride=2)\n",
    "#         self.layer3 = self._make_layer(block, 256, num_blocks[2], stride=2)\n",
    "#         self.layer4 = self._make_layer(block, 512, num_blocks[3], stride=2)\n",
    "#         self.avgpool = nn.AdaptiveAvgPool2d((1, 1))\n",
    "#         self.fc = nn.Linear(512 * block.expansion, num_classes)\n",
    "\n",
    "#     def _make_layer(self, block, planes, num_blocks, stride):\n",
    "#         strides = [stride] + [1]*(num_blocks-1)\n",
    "#         layers = []\n",
    "#         for stride in strides:\n",
    "#             layers.append(block(self.in_planes, planes, stride))\n",
    "#             self.in_planes = planes * block.expansion\n",
    "#         return nn.Sequential(*layers)\n",
    "\n",
    "#     def forward(self, x):\n",
    "#         out = F.relu(self.bn1(self.conv1(x)))\n",
    "#         out = self.layer1(out)\n",
    "#         out = self.layer2(out)\n",
    "#         out = self.layer3(out)\n",
    "#         out = self.layer4(out)\n",
    "#         out = self.avgpool(out)\n",
    "#         out = out.view(out.size(0), -1)\n",
    "#         out = self.fc(out)\n",
    "#         return out\n",
    "\n",
    "# def EmotionClassifierResNet18():\n",
    "#     return ResNet(BasicBlock, [2, 2, 2, 2])\n",
    "\n",
    "# model = EmotionClassifierResNet18().to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# param_grid = {\n",
    "#     'lr': [0.1, 0.01, 0.001, 0.0001], \n",
    "#     'batch_size': [8, 16, 32, 64],  \n",
    "# }\n",
    "# grid = ParameterGrid(param_grid)\n",
    "# results = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for params in grid: # Hyperparameter tuning \n",
    "#     data_train_loader = DataLoader(rafdb_dataset_train, batch_size=params['batch_size'], shuffle=True, num_workers=4)\n",
    "#     data_vali_loader = DataLoader(rafdb_dataset_vali, batch_size=params['batch_size'], shuffle=False, num_workers=0)\n",
    "    \n",
    "#     model = EmotionClassifier().to(device)\n",
    "#     optimizer = optim.Adam(model.parameters(), lr=params['lr'])\n",
    "#     criterion = nn.CrossEntropyLoss()\n",
    "    \n",
    "#     best_val_acc = 0\n",
    "#     num_epochs = 15\n",
    "    \n",
    "#     for epoch in range(num_epochs):\n",
    "#         model.train()\n",
    "#         for i, data in enumerate(tqdm(data_train_loader, desc=f\"Epoch {epoch+1}/{num_epochs}\"), 0):\n",
    "#             inputs, labels = data[0].to(device), data[1].to(device)\n",
    "#             optimizer.zero_grad()\n",
    "#             outputs = model(inputs)\n",
    "#             loss = criterion(outputs, labels)\n",
    "#             loss.backward()\n",
    "#             optimizer.step()\n",
    "\n",
    "#     model.eval()\n",
    "#     val_correct = 0\n",
    "#     val_total = 0\n",
    "#     with torch.no_grad():\n",
    "#         for data in data_vali_loader:\n",
    "#             inputs, labels = data[0].to(device), data[1].to(device)\n",
    "#             outputs = model(inputs)\n",
    "#             _, predicted = torch.max(outputs.data, 1)\n",
    "#             val_total += labels.size(0)\n",
    "#             val_correct += (predicted == labels).sum().item()\n",
    "    \n",
    "#     val_acc = val_correct / val_total\n",
    "#     best_val_acc = max(best_val_acc, val_acc)\n",
    "    \n",
    "#     results.append({\n",
    "#         'lr': params['lr'],\n",
    "#         'batch_size': params['batch_size'],\n",
    "#         'best_val_acc': best_val_acc,\n",
    "#     })\n",
    "\n",
    "# for result in results:\n",
    "#     print(f\"LR: {result['lr']}, Batch Size: {result['batch_size']}, Best Val Acc: {result['best_val_acc']}\")\n",
    "\n",
    "# best_params = max(results, key=lambda x: x['best_val_acc'])\n",
    "# print(f\"Best params: {best_params}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "# optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "# optimizer = optim.Adam(model.parameters(), lr=0.001, amsgrad=True)\n",
    "# optimizer = optim.AdamW(model.parameters(), lr=0.001, weight_decay=1e-5)\n",
    "# optimizer = optim.SGD(model.parameters(), lr=0.01, momentum=0.9, nesterov=True)\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.001, momentum=0.9, weight_decay=1e-4)\n",
    "\n",
    "\n",
    "patience = 15\n",
    "best_val_acc = 0  \n",
    "patience_counter = 0\n",
    "\n",
    "num_epochs = 80"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/80: 100%|██████████| 610/610 [00:45<00:00, 13.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Train Loss: 1.3765998897982425, Train Accuracy: 0.4935358095628976, Test Loss: 1.4543855595588684, Test Accuracy: 0.49727691663175533, Validation Loss: 2.4610698630935266, Validation Accuracy: 0.1686143572621035\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/80: 100%|██████████| 610/610 [00:45<00:00, 13.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2, Train Loss: 1.2574041151609576, Train Accuracy: 0.5358095628975991, Test Loss: 1.4450261031587919, Test Accuracy: 0.5245077503142019, Validation Loss: 2.560710078791568, Validation Accuracy: 0.21035058430717862\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/80: 100%|██████████| 610/610 [00:45<00:00, 13.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3, Train Loss: 1.1133446943564493, Train Accuracy: 0.5892673917504617, Test Loss: 1.0622586748997371, Test Accuracy: 0.6154168412232929, Validation Loss: 1.9728685993897288, Validation Accuracy: 0.31385642737896496\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/80: 100%|██████████| 610/610 [00:45<00:00, 13.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4, Train Loss: 0.9990400203427331, Train Accuracy: 0.6402626718653807, Test Loss: 0.9659165557225545, Test Accuracy: 0.6539589442815249, Validation Loss: 1.673867382501301, Validation Accuracy: 0.39065108514190316\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/80: 100%|██████████| 610/610 [00:45<00:00, 13.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5, Train Loss: 0.9043094027726377, Train Accuracy: 0.6778165401190231, Test Loss: 0.8847861917379002, Test Accuracy: 0.6983661499790532, Validation Loss: 1.7760477191523503, Validation Accuracy: 0.41736227045075125\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6/80: 100%|██████████| 610/610 [00:45<00:00, 13.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6, Train Loss: 0.8238150859465364, Train Accuracy: 0.7078801559614201, Test Loss: 0.7840002653747797, Test Accuracy: 0.7381650607457059, Validation Loss: 1.42940554493352, Validation Accuracy: 0.49248747913188645\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7/80: 100%|██████████| 610/610 [00:45<00:00, 13.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7, Train Loss: 0.7779673532872904, Train Accuracy: 0.719577262466653, Test Loss: 0.7157164648175239, Test Accuracy: 0.754084625052367, Validation Loss: 1.454172217532208, Validation Accuracy: 0.4991652754590985\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8/80: 100%|██████████| 610/610 [00:45<00:00, 13.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8, Train Loss: 0.736006154413106, Train Accuracy: 0.7358916478555305, Test Loss: 0.7873710527239989, Test Accuracy: 0.7385839966485128, Validation Loss: 1.5427075404869883, Validation Accuracy: 0.48580968280467446\n",
      "No improvement in validation accuracy for 1 epochs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9/80: 100%|██████████| 610/610 [00:45<00:00, 13.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9, Train Loss: 0.6953895998782799, Train Accuracy: 0.751282577467679, Test Loss: 0.6540453974592189, Test Accuracy: 0.7779639715123586, Validation Loss: 1.387228388535349, Validation Accuracy: 0.5308848080133556\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/80: 100%|██████████| 610/610 [00:45<00:00, 13.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10, Train Loss: 0.6657527811214572, Train Accuracy: 0.7622614405910118, Test Loss: 0.604961874447763, Test Accuracy: 0.7972350230414746, Validation Loss: 1.1944092402332707, Validation Accuracy: 0.5843071786310517\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 11/80: 100%|██████████| 610/610 [00:45<00:00, 13.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11, Train Loss: 0.6306585620661251, Train Accuracy: 0.7775497640057459, Test Loss: 0.6083984733993808, Test Accuracy: 0.7984918307498953, Validation Loss: 1.1976830708353143, Validation Accuracy: 0.5859766277128547\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 12/80: 100%|██████████| 610/610 [00:46<00:00, 13.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12, Train Loss: 0.6145916915086449, Train Accuracy: 0.7811409809152473, Test Loss: 0.5952112052962184, Test Accuracy: 0.7984918307498953, Validation Loss: 1.1679706777396954, Validation Accuracy: 0.5926544240400667\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 13/80: 100%|██████████| 610/610 [00:45<00:00, 13.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13, Train Loss: 0.5893693524183797, Train Accuracy: 0.7909911758670224, Test Loss: 0.5565078528039158, Test Accuracy: 0.8152492668621701, Validation Loss: 1.1436472597875094, Validation Accuracy: 0.6243739565943238\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 14/80: 100%|██████████| 610/610 [00:45<00:00, 13.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14, Train Loss: 0.5801352381217675, Train Accuracy: 0.8000205212394829, Test Loss: 0.5638876891260346, Test Accuracy: 0.8139924591537495, Validation Loss: 1.1668302808937274, Validation Accuracy: 0.6293823038397329\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 15/80: 100%|██████████| 610/610 [00:45<00:00, 13.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15, Train Loss: 0.5526844626078841, Train Accuracy: 0.8016622203981121, Test Loss: 0.5436410147572557, Test Accuracy: 0.8165060745705907, Validation Loss: 1.0892476706128371, Validation Accuracy: 0.6460767946577629\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 16/80: 100%|██████████| 610/610 [00:45<00:00, 13.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16, Train Loss: 0.5365704442817169, Train Accuracy: 0.8124358711266161, Test Loss: 0.5530681245184194, Test Accuracy: 0.8173439463762044, Validation Loss: 1.1329340809269954, Validation Accuracy: 0.6377295492487479\n",
      "No improvement in validation accuracy for 1 epochs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 17/80: 100%|██████████| 610/610 [00:45<00:00, 13.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17, Train Loss: 0.5233084035335017, Train Accuracy: 0.8144879950749025, Test Loss: 0.5419179718755186, Test Accuracy: 0.8139924591537495, Validation Loss: 0.9952216775793779, Validation Accuracy: 0.664440734557596\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 18/80: 100%|██████████| 610/610 [00:45<00:00, 13.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18, Train Loss: 0.5119163614438206, Train Accuracy: 0.8160270880361173, Test Loss: 0.5252177409331004, Test Accuracy: 0.8177628822790113, Validation Loss: 0.8577406288761842, Validation Accuracy: 0.6811352253756261\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 19/80: 100%|██████████| 610/610 [00:45<00:00, 13.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19, Train Loss: 0.48309401079523756, Train Accuracy: 0.8309049866611944, Test Loss: 0.5597567103865246, Test Accuracy: 0.8123167155425219, Validation Loss: 1.1058103755900734, Validation Accuracy: 0.6377295492487479\n",
      "No improvement in validation accuracy for 1 epochs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 20/80: 100%|██████████| 610/610 [00:45<00:00, 13.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20, Train Loss: 0.4761941325224814, Train Accuracy: 0.8328545044120665, Test Loss: 0.4948379107067982, Test Accuracy: 0.8353581901968998, Validation Loss: 0.9339871147745534, Validation Accuracy: 0.6978297161936561\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 21/80: 100%|██████████| 610/610 [00:45<00:00, 13.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 21, Train Loss: 0.46733423713900024, Train Accuracy: 0.8341883849784527, Test Loss: 0.5241363753005862, Test Accuracy: 0.8232090490155006, Validation Loss: 1.0195943281838769, Validation Accuracy: 0.669449081803005\n",
      "No improvement in validation accuracy for 1 epochs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 22/80: 100%|██████████| 610/610 [00:45<00:00, 13.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 22, Train Loss: 0.44248735395977734, Train Accuracy: 0.8420890621793556, Test Loss: 0.5768257623142563, Test Accuracy: 0.8165060745705907, Validation Loss: 1.1321393306318082, Validation Accuracy: 0.657762938230384\n",
      "No improvement in validation accuracy for 2 epochs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 23/80: 100%|██████████| 610/610 [00:45<00:00, 13.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 23, Train Loss: 0.432204544727431, Train Accuracy: 0.8461933100759286, Test Loss: 0.5434299280991157, Test Accuracy: 0.8257226644323419, Validation Loss: 1.0791316612770683, Validation Accuracy: 0.657762938230384\n",
      "No improvement in validation accuracy for 3 epochs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 24/80: 100%|██████████| 610/610 [00:45<00:00, 13.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24, Train Loss: 0.4198956777082115, Train Accuracy: 0.8517340447363021, Test Loss: 0.5210027886430423, Test Accuracy: 0.8186007540846251, Validation Loss: 0.9366604811266849, Validation Accuracy: 0.6894824707846411\n",
      "No improvement in validation accuracy for 4 epochs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 25/80: 100%|██████████| 610/610 [00:46<00:00, 13.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 25, Train Loss: 0.41074026437690025, Train Accuracy: 0.8570695670018469, Test Loss: 0.5766532888108243, Test Accuracy: 0.8102220360284876, Validation Loss: 1.0160825879950273, Validation Accuracy: 0.6811352253756261\n",
      "No improvement in validation accuracy for 5 epochs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 26/80: 100%|██████████| 610/610 [00:45<00:00, 13.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 26, Train Loss: 0.39635026017661956, Train Accuracy: 0.8609686025035912, Test Loss: 0.4945898161145548, Test Accuracy: 0.8408043569333892, Validation Loss: 0.9274849326987016, Validation Accuracy: 0.7078464106844741\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 27/80: 100%|██████████| 610/610 [00:46<00:00, 13.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 27, Train Loss: 0.38264932750922737, Train Accuracy: 0.8617894520829058, Test Loss: 0.5596740935308238, Test Accuracy: 0.8190196899874319, Validation Loss: 1.0062892672262693, Validation Accuracy: 0.664440734557596\n",
      "No improvement in validation accuracy for 1 epochs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 28/80: 100%|██████████| 610/610 [00:46<00:00, 13.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 28, Train Loss: 0.3645916356338707, Train Accuracy: 0.8728709214036527, Test Loss: 0.5110540566143269, Test Accuracy: 0.8378718056137411, Validation Loss: 0.9855044295913294, Validation Accuracy: 0.7078464106844741\n",
      "No improvement in validation accuracy for 2 epochs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 29/80: 100%|██████████| 610/610 [00:46<00:00, 13.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 29, Train Loss: 0.36685146566663607, Train Accuracy: 0.871331828442438, Test Loss: 0.4694682212856909, Test Accuracy: 0.8496020108923334, Validation Loss: 0.9849302305987007, Validation Accuracy: 0.6878130217028381\n",
      "No improvement in validation accuracy for 3 epochs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 30/80: 100%|██████████| 610/610 [00:46<00:00, 13.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 30, Train Loss: 0.35159545852268326, Train Accuracy: 0.8778986250769546, Test Loss: 0.5113984572130721, Test Accuracy: 0.8466694595726854, Validation Loss: 1.0402857959270477, Validation Accuracy: 0.679465776293823\n",
      "No improvement in validation accuracy for 4 epochs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 31/80: 100%|██████████| 610/610 [00:45<00:00, 13.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 31, Train Loss: 0.34591530482284727, Train Accuracy: 0.878001231274369, Test Loss: 0.5014795144585271, Test Accuracy: 0.8303309593632174, Validation Loss: 0.885557238600756, Validation Accuracy: 0.7228714524207012\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 32/80: 100%|██████████| 610/610 [00:46<00:00, 13.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 32, Train Loss: 0.3259031200689859, Train Accuracy: 0.8847732403037143, Test Loss: 0.5272079390574557, Test Accuracy: 0.8449937159614579, Validation Loss: 1.0899028981986798, Validation Accuracy: 0.6928213689482471\n",
      "No improvement in validation accuracy for 1 epochs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 33/80: 100%|██████████| 610/610 [00:46<00:00, 13.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 33, Train Loss: 0.32131375635546616, Train Accuracy: 0.8894931253847732, Test Loss: 0.5139191147731617, Test Accuracy: 0.834939254294093, Validation Loss: 1.0268658172143132, Validation Accuracy: 0.6911519198664441\n",
      "No improvement in validation accuracy for 2 epochs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 34/80: 100%|██████████| 610/610 [00:45<00:00, 13.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 34, Train Loss: 0.3203990333820464, Train Accuracy: 0.8854914836856146, Test Loss: 0.4875431373684357, Test Accuracy: 0.8496020108923334, Validation Loss: 0.9657508452471933, Validation Accuracy: 0.7161936560934892\n",
      "No improvement in validation accuracy for 3 epochs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 35/80: 100%|██████████| 610/610 [00:45<00:00, 13.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 35, Train Loss: 0.296403803624457, Train Accuracy: 0.895752103427047, Test Loss: 0.619582176967524, Test Accuracy: 0.8232090490155006, Validation Loss: 1.1567828184679936, Validation Accuracy: 0.6811352253756261\n",
      "No improvement in validation accuracy for 4 epochs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 36/80: 100%|██████████| 610/610 [00:45<00:00, 13.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 36, Train Loss: 0.29784522481934456, Train Accuracy: 0.8947260414529038, Test Loss: 0.5148653349280358, Test Accuracy: 0.8378718056137411, Validation Loss: 0.956295393015209, Validation Accuracy: 0.7078464106844741\n",
      "No improvement in validation accuracy for 5 epochs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 37/80: 100%|██████████| 610/610 [00:45<00:00, 13.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 37, Train Loss: 0.2870287560323467, Train Accuracy: 0.8994459265339626, Test Loss: 0.5462641606184965, Test Accuracy: 0.8307498952660243, Validation Loss: 0.9772712443219987, Validation Accuracy: 0.7028380634390651\n",
      "No improvement in validation accuracy for 6 epochs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 38/80: 100%|██████████| 610/610 [00:45<00:00, 13.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 38, Train Loss: 0.2727084962490824, Train Accuracy: 0.9017032628770778, Test Loss: 0.5119344728284826, Test Accuracy: 0.8508588186007541, Validation Loss: 1.1206358302580683, Validation Accuracy: 0.6944908180300501\n",
      "No improvement in validation accuracy for 7 epochs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 39/80: 100%|██████████| 610/610 [00:45<00:00, 13.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 39, Train Loss: 0.26809308937766024, Train Accuracy: 0.9045762364046789, Test Loss: 0.5489195190335159, Test Accuracy: 0.8307498952660243, Validation Loss: 1.0201959562929053, Validation Accuracy: 0.7045075125208681\n",
      "No improvement in validation accuracy for 8 epochs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 40/80: 100%|██████████| 610/610 [00:45<00:00, 13.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 40, Train Loss: 0.26357670125597327, Train Accuracy: 0.9052944797865791, Test Loss: 0.5650943707674742, Test Accuracy: 0.8265605362379556, Validation Loss: 0.9651609972903603, Validation Accuracy: 0.7278797996661102\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 41/80: 100%|██████████| 610/610 [00:45<00:00, 13.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 41, Train Loss: 0.2566056968430515, Train Accuracy: 0.9058075107736507, Test Loss: 0.5200274051850041, Test Accuracy: 0.8441558441558441, Validation Loss: 0.9834040654333014, Validation Accuracy: 0.7212020033388982\n",
      "No improvement in validation accuracy for 1 epochs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 42/80: 100%|██████████| 610/610 [00:45<00:00, 13.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 42, Train Loss: 0.23657779466269202, Train Accuracy: 0.9162733429099118, Test Loss: 0.4953618416485066, Test Accuracy: 0.8563049853372434, Validation Loss: 0.9675407174386477, Validation Accuracy: 0.7278797996661102\n",
      "No improvement in validation accuracy for 2 epochs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 43/80: 100%|██████████| 610/610 [00:45<00:00, 13.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 43, Train Loss: 0.23431018091848915, Train Accuracy: 0.9178124358711266, Test Loss: 0.507431059764543, Test Accuracy: 0.8537913699204022, Validation Loss: 1.0312070658332424, Validation Accuracy: 0.7262103505843072\n",
      "No improvement in validation accuracy for 3 epochs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 44/80: 100%|██████████| 610/610 [00:46<00:00, 13.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 44, Train Loss: 0.23520663786129872, Train Accuracy: 0.9152472809357686, Test Loss: 0.5142096840823069, Test Accuracy: 0.8525345622119815, Validation Loss: 1.0513745648296255, Validation Accuracy: 0.7195325542570952\n",
      "No improvement in validation accuracy for 4 epochs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 45/80: 100%|██████████| 610/610 [00:45<00:00, 13.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 45, Train Loss: 0.21699554405068278, Train Accuracy: 0.9261235378616869, Test Loss: 0.556557598868385, Test Accuracy: 0.8353581901968998, Validation Loss: 0.927517927790943, Validation Accuracy: 0.7328881469115192\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 46/80: 100%|██████████| 610/610 [00:45<00:00, 13.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 46, Train Loss: 0.21781398037975258, Train Accuracy: 0.9221218961625283, Test Loss: 0.5490251500729937, Test Accuracy: 0.8491830749895266, Validation Loss: 1.0245565987731282, Validation Accuracy: 0.7245409015025042\n",
      "No improvement in validation accuracy for 1 epochs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 47/80: 100%|██████████| 610/610 [00:45<00:00, 13.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 47, Train Loss: 0.2169915274480266, Train Accuracy: 0.9254052944797866, Test Loss: 0.5035767838327835, Test Accuracy: 0.8437369082530373, Validation Loss: 0.83443964508019, Validation Accuracy: 0.7495826377295493\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 48/80: 100%|██████████| 610/610 [00:45<00:00, 13.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 48, Train Loss: 0.20989898931097667, Train Accuracy: 0.9235583829263287, Test Loss: 0.5543197862710804, Test Accuracy: 0.847926267281106, Validation Loss: 1.1458379155711125, Validation Accuracy: 0.6911519198664441\n",
      "No improvement in validation accuracy for 1 epochs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 49/80: 100%|██████████| 610/610 [00:45<00:00, 13.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 49, Train Loss: 0.20247466763534935, Train Accuracy: 0.924584444900472, Test Loss: 0.6576272147161459, Test Accuracy: 0.8399664851277755, Validation Loss: 1.409368304045577, Validation Accuracy: 0.672787979966611\n",
      "No improvement in validation accuracy for 2 epochs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 50/80: 100%|██████████| 610/610 [00:45<00:00, 13.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 50, Train Loss: 0.19536358284893765, Train Accuracy: 0.9285860865996306, Test Loss: 0.5283034879535747, Test Accuracy: 0.8533724340175953, Validation Loss: 1.0076876149365777, Validation Accuracy: 0.7362270450751253\n",
      "No improvement in validation accuracy for 3 epochs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 51/80: 100%|██████████| 610/610 [00:45<00:00, 13.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 51, Train Loss: 0.1967210039675816, Train Accuracy: 0.9295095423763595, Test Loss: 0.5454278037374994, Test Accuracy: 0.8504398826979472, Validation Loss: 1.14254755722849, Validation Accuracy: 0.7111853088480802\n",
      "No improvement in validation accuracy for 4 epochs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 52/80: 100%|██████████| 610/610 [00:45<00:00, 13.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 52, Train Loss: 0.18563506075135264, Train Accuracy: 0.9336137902729325, Test Loss: 0.5168787108361721, Test Accuracy: 0.857561793045664, Validation Loss: 1.0812015251109475, Validation Accuracy: 0.7328881469115192\n",
      "No improvement in validation accuracy for 5 epochs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 53/80: 100%|██████████| 610/610 [00:45<00:00, 13.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 53, Train Loss: 0.17347986082370837, Train Accuracy: 0.9367945823927766, Test Loss: 0.5415396006102674, Test Accuracy: 0.8491830749895266, Validation Loss: 0.9734834546321317, Validation Accuracy: 0.7445742904841403\n",
      "No improvement in validation accuracy for 6 epochs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 54/80: 100%|██████████| 610/610 [00:45<00:00, 13.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 54, Train Loss: 0.1658790378644299, Train Accuracy: 0.9419248922634927, Test Loss: 0.5818256710311592, Test Accuracy: 0.8558860494344366, Validation Loss: 1.2515766353983628, Validation Accuracy: 0.7212020033388982\n",
      "No improvement in validation accuracy for 7 epochs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 55/80: 100%|██████████| 610/610 [00:45<00:00, 13.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 55, Train Loss: 0.17346031408123366, Train Accuracy: 0.9369997947876052, Test Loss: 0.5526712929610706, Test Accuracy: 0.8496020108923334, Validation Loss: 1.1346867907988398, Validation Accuracy: 0.7111853088480802\n",
      "No improvement in validation accuracy for 8 epochs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 56/80: 100%|██████████| 610/610 [00:45<00:00, 13.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 56, Train Loss: 0.16055359634662383, Train Accuracy: 0.9441822286066078, Test Loss: 0.5527689851166118, Test Accuracy: 0.8600754084625052, Validation Loss: 1.0230263248085976, Validation Accuracy: 0.7495826377295493\n",
      "No improvement in validation accuracy for 9 epochs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 57/80: 100%|██████████| 610/610 [00:45<00:00, 13.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 57, Train Loss: 0.15603815900330284, Train Accuracy: 0.9438744100143649, Test Loss: 0.5701464145826078, Test Accuracy: 0.8596564725596983, Validation Loss: 1.180044193801127, Validation Accuracy: 0.7362270450751253\n",
      "No improvement in validation accuracy for 10 epochs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 58/80: 100%|██████████| 610/610 [00:45<00:00, 13.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 58, Train Loss: 0.15455408454102132, Train Accuracy: 0.9456187153704084, Test Loss: 0.6093896305275848, Test Accuracy: 0.8571428571428571, Validation Loss: 1.245890081713074, Validation Accuracy: 0.7228714524207012\n",
      "No improvement in validation accuracy for 11 epochs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 59/80: 100%|██████████| 610/610 [00:45<00:00, 13.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 59, Train Loss: 0.15060112932773276, Train Accuracy: 0.9456187153704084, Test Loss: 0.6170810931319526, Test Accuracy: 0.8403854210305823, Validation Loss: 1.1686939526545375, Validation Accuracy: 0.7262103505843072\n",
      "No improvement in validation accuracy for 12 epochs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 60/80: 100%|██████████| 610/610 [00:45<00:00, 13.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 60, Train Loss: 0.13999895192930842, Train Accuracy: 0.949312538477324, Test Loss: 0.6144475544504046, Test Accuracy: 0.8491830749895266, Validation Loss: 1.2907191985531856, Validation Accuracy: 0.7111853088480802\n",
      "No improvement in validation accuracy for 13 epochs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 61/80: 100%|██████████| 610/610 [00:45<00:00, 13.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 61, Train Loss: 0.14730431832121227, Train Accuracy: 0.94613174635748, Test Loss: 0.5325883601373061, Test Accuracy: 0.8588186007540847, Validation Loss: 1.0042492739464108, Validation Accuracy: 0.7579298831385642\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 62/80: 100%|██████████| 610/610 [00:45<00:00, 13.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 62, Train Loss: 0.13825895629539803, Train Accuracy: 0.9513646624256105, Test Loss: 0.5759722454073684, Test Accuracy: 0.8558860494344366, Validation Loss: 1.1627761364767426, Validation Accuracy: 0.7262103505843072\n",
      "No improvement in validation accuracy for 1 epochs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 63/80: 100%|██████████| 610/610 [00:45<00:00, 13.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 63, Train Loss: 0.1315031280712469, Train Accuracy: 0.9538272111635543, Test Loss: 0.614875148505865, Test Accuracy: 0.8563049853372434, Validation Loss: 1.2947207869667756, Validation Accuracy: 0.7245409015025042\n",
      "No improvement in validation accuracy for 2 epochs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 64/80: 100%|██████████| 610/610 [00:45<00:00, 13.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 64, Train Loss: 0.1289420125996465, Train Accuracy: 0.953108967781654, Test Loss: 0.6388315195590257, Test Accuracy: 0.8449937159614579, Validation Loss: 1.164969843469168, Validation Accuracy: 0.7445742904841403\n",
      "No improvement in validation accuracy for 3 epochs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 65/80: 100%|██████████| 610/610 [00:45<00:00, 13.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 65, Train Loss: 0.12841868430555448, Train Accuracy: 0.9553663041247691, Test Loss: 0.596182693100612, Test Accuracy: 0.8529534981147885, Validation Loss: 1.1584805846214294, Validation Accuracy: 0.7462437395659433\n",
      "No improvement in validation accuracy for 4 epochs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 66/80: 100%|██████████| 610/610 [00:46<00:00, 13.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 66, Train Loss: 0.12344416192258886, Train Accuracy: 0.9551610917299405, Test Loss: 0.6685332367747227, Test Accuracy: 0.854210305823209, Validation Loss: 1.4071627761188306, Validation Accuracy: 0.7111853088480802\n",
      "No improvement in validation accuracy for 5 epochs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 67/80: 100%|██████████| 610/610 [00:45<00:00, 13.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 67, Train Loss: 0.11456227014654748, Train Accuracy: 0.9605992201928997, Test Loss: 0.5763119649792012, Test Accuracy: 0.8563049853372434, Validation Loss: 1.0095685351836055, Validation Accuracy: 0.7729549248747913\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 68/80: 100%|██████████| 610/610 [00:45<00:00, 13.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 68, Train Loss: 0.11861559466733673, Train Accuracy: 0.9577262466652986, Test Loss: 0.5596412339866704, Test Accuracy: 0.8638458315877671, Validation Loss: 1.0604514761974937, Validation Accuracy: 0.7679465776293823\n",
      "No improvement in validation accuracy for 1 epochs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 69/80: 100%|██████████| 610/610 [00:45<00:00, 13.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 69, Train Loss: 0.11560336288801401, Train Accuracy: 0.9574184280730557, Test Loss: 0.5689473758762081, Test Accuracy: 0.8617511520737328, Validation Loss: 1.1225917284425937, Validation Accuracy: 0.7545909849749582\n",
      "No improvement in validation accuracy for 2 epochs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 70/80: 100%|██████████| 610/610 [00:45<00:00, 13.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 70, Train Loss: 0.10266438643705696, Train Accuracy: 0.9637800123127437, Test Loss: 0.6783089286111257, Test Accuracy: 0.8537913699204022, Validation Loss: 1.441120938250893, Validation Accuracy: 0.7145242070116862\n",
      "No improvement in validation accuracy for 3 epochs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 71/80: 100%|██████████| 610/610 [00:45<00:00, 13.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 71, Train Loss: 0.10505255572240205, Train Accuracy: 0.9641904371024009, Test Loss: 0.5827992253970782, Test Accuracy: 0.8638458315877671, Validation Loss: 1.0996013522932404, Validation Accuracy: 0.7445742904841403\n",
      "No improvement in validation accuracy for 4 epochs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 72/80: 100%|██████████| 610/610 [00:46<00:00, 13.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 72, Train Loss: 0.10375708398365294, Train Accuracy: 0.9639852247075723, Test Loss: 0.5711681207648508, Test Accuracy: 0.8646837033933809, Validation Loss: 1.2030316489307504, Validation Accuracy: 0.7579298831385642\n",
      "No improvement in validation accuracy for 5 epochs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 73/80: 100%|██████████| 610/610 [00:45<00:00, 13.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 73, Train Loss: 0.0997973572113074, Train Accuracy: 0.9636774061153294, Test Loss: 0.6000052911206148, Test Accuracy: 0.8625890238793464, Validation Loss: 1.0698488818383531, Validation Accuracy: 0.7662771285475793\n",
      "No improvement in validation accuracy for 6 epochs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 74/80: 100%|██████████| 610/610 [00:45<00:00, 13.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 74, Train Loss: 0.09940897352043081, Train Accuracy: 0.9659347424584445, Test Loss: 0.7065069831572812, Test Accuracy: 0.841223292836196, Validation Loss: 1.3967211332760359, Validation Accuracy: 0.7061769616026711\n",
      "No improvement in validation accuracy for 7 epochs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 75/80: 100%|██████████| 610/610 [00:46<00:00, 13.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 75, Train Loss: 0.1008809890009541, Train Accuracy: 0.9649086804843012, Test Loss: 0.6714028774016576, Test Accuracy: 0.8428990364474236, Validation Loss: 1.2139574301085974, Validation Accuracy: 0.7512520868113522\n",
      "No improvement in validation accuracy for 8 epochs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 76/80: 100%|██████████| 610/610 [00:45<00:00, 13.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 76, Train Loss: 0.10340349390705833, Train Accuracy: 0.9625487379437718, Test Loss: 0.6111635814284091, Test Accuracy: 0.8638458315877671, Validation Loss: 1.2573265815643888, Validation Accuracy: 0.7495826377295493\n",
      "No improvement in validation accuracy for 9 epochs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 77/80: 100%|██████████| 610/610 [00:45<00:00, 13.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 77, Train Loss: 0.10671966547556995, Train Accuracy: 0.9619331007592858, Test Loss: 0.631516252256503, Test Accuracy: 0.8604943443653121, Validation Loss: 1.3271358491558778, Validation Accuracy: 0.7245409015025042\n",
      "No improvement in validation accuracy for 10 epochs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 78/80: 100%|██████████| 610/610 [00:45<00:00, 13.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 78, Train Loss: 0.08739613418683952, Train Accuracy: 0.968294684998974, Test Loss: 0.5798055074039439, Test Accuracy: 0.8651026392961877, Validation Loss: 1.1585459309188944, Validation Accuracy: 0.7412353923205343\n",
      "No improvement in validation accuracy for 11 epochs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 79/80: 100%|██████████| 610/610 [00:45<00:00, 13.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 79, Train Loss: 0.09399375307944328, Train Accuracy: 0.9684998973938026, Test Loss: 0.5919819464498142, Test Accuracy: 0.8592375366568915, Validation Loss: 1.2561632716342022, Validation Accuracy: 0.7328881469115192\n",
      "No improvement in validation accuracy for 12 epochs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 80/80: 100%|██████████| 610/610 [00:45<00:00, 13.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 80, Train Loss: 0.08560060318626204, Train Accuracy: 0.9699363841576031, Test Loss: 0.649371515357246, Test Accuracy: 0.8378718056137411, Validation Loss: 0.9809991403629905, Validation Accuracy: 0.7813021702838063\n"
     ]
    }
   ],
   "source": [
    "train_losses = []\n",
    "val_losses = []\n",
    "train_accuracies = []\n",
    "val_accuracies = []\n",
    "test_losses = []\n",
    "test_accuracies = []\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    for data in tqdm(data_train_loader, desc=f\"Epoch {epoch+1}/{num_epochs}\"):\n",
    "        inputs, labels = data[0].to(device), data[1].to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "    train_loss = running_loss / len(data_train_loader)\n",
    "    train_acc = correct / total\n",
    "    train_losses.append(train_loss)\n",
    "    train_accuracies.append(train_acc)\n",
    "\n",
    "    model.eval()\n",
    "    test_running_loss = 0.0\n",
    "    test_correct = 0\n",
    "    test_total = 0\n",
    "    with torch.no_grad():\n",
    "        for data in data_test_loader:\n",
    "            inputs, labels = data[0].to(device), data[1].to(device)\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            test_running_loss += loss.item()\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            test_total += labels.size(0)\n",
    "            test_correct += (predicted == labels).sum().item()\n",
    "\n",
    "    test_loss = test_running_loss / len(data_test_loader)\n",
    "    test_acc = test_correct / test_total\n",
    "    test_losses.append(test_loss)\n",
    "    test_accuracies.append(test_acc)\n",
    "\n",
    "    model.eval()\n",
    "    val_running_loss = 0.0\n",
    "    val_correct = 0\n",
    "    val_total = 0\n",
    "    with torch.no_grad():\n",
    "        for data in data_vali_loader:\n",
    "            inputs, labels = data[0].to(device), data[1].to(device)\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            val_running_loss += loss.item()\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            val_total += labels.size(0)\n",
    "            val_correct += (predicted == labels).sum().item()\n",
    "\n",
    "    val_loss = val_running_loss / len(data_vali_loader)\n",
    "    val_acc = val_correct / val_total\n",
    "    val_losses.append(val_loss)\n",
    "    val_accuracies.append(val_acc)\n",
    "\n",
    "    print(f\"Epoch {epoch+1}, Train Loss: {train_loss}, Train Accuracy: {train_acc}, Test Loss: {test_loss}, Test Accuracy: {test_acc}, Validation Loss: {val_loss}, Validation Accuracy: {val_acc}\")\n",
    "\n",
    "    if val_acc > best_val_acc:\n",
    "        best_val_acc = val_acc\n",
    "        patience_counter = 0 \n",
    "        torch.save(model.state_dict(), 'best_model.pth')\n",
    "    else:\n",
    "        patience_counter += 1\n",
    "        print(f\"No improvement in validation accuracy for {patience_counter} epochs.\")\n",
    "    \n",
    "    if patience_counter > patience:\n",
    "        print(\"Stopping early due to lack of improvement in validation accuracy.\")\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "x and y must have same first dimension, but have shapes (79,) and (80,)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[16], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m plt\u001b[38;5;241m.\u001b[39mfigure(figsize\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m15\u001b[39m, \u001b[38;5;241m7\u001b[39m))\n\u001b[1;32m      2\u001b[0m plt\u001b[38;5;241m.\u001b[39msubplot(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m----> 3\u001b[0m \u001b[43mplt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mplot\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mrange\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m80\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_losses\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mTrain Loss\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;66;03m# change this number after '(1, _)' to num_epochs+1\u001b[39;00m\n\u001b[1;32m      4\u001b[0m plt\u001b[38;5;241m.\u001b[39mplot(\u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m80\u001b[39m), test_losses, label\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTest Loss\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;66;03m# change this number after '(1, _)' to num_epochs+1\u001b[39;00m\n\u001b[1;32m      5\u001b[0m plt\u001b[38;5;241m.\u001b[39mplot(\u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m80\u001b[39m), val_losses, label\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mValidation Loss\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;66;03m# change this number after '(1, _)' to num_epochs+1\u001b[39;00m\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/matplotlib/pyplot.py:3575\u001b[0m, in \u001b[0;36mplot\u001b[0;34m(scalex, scaley, data, *args, **kwargs)\u001b[0m\n\u001b[1;32m   3567\u001b[0m \u001b[38;5;129m@_copy_docstring_and_deprecators\u001b[39m(Axes\u001b[38;5;241m.\u001b[39mplot)\n\u001b[1;32m   3568\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mplot\u001b[39m(\n\u001b[1;32m   3569\u001b[0m     \u001b[38;5;241m*\u001b[39margs: \u001b[38;5;28mfloat\u001b[39m \u001b[38;5;241m|\u001b[39m ArrayLike \u001b[38;5;241m|\u001b[39m \u001b[38;5;28mstr\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   3573\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[1;32m   3574\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mlist\u001b[39m[Line2D]:\n\u001b[0;32m-> 3575\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mgca\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mplot\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   3576\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3577\u001b[0m \u001b[43m        \u001b[49m\u001b[43mscalex\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mscalex\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3578\u001b[0m \u001b[43m        \u001b[49m\u001b[43mscaley\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mscaley\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3579\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mdata\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m}\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mis\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3580\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3581\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/matplotlib/axes/_axes.py:1721\u001b[0m, in \u001b[0;36mAxes.plot\u001b[0;34m(self, scalex, scaley, data, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1478\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1479\u001b[0m \u001b[38;5;124;03mPlot y versus x as lines and/or markers.\u001b[39;00m\n\u001b[1;32m   1480\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1718\u001b[0m \u001b[38;5;124;03m(``'green'``) or hex strings (``'#008000'``).\u001b[39;00m\n\u001b[1;32m   1719\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1720\u001b[0m kwargs \u001b[38;5;241m=\u001b[39m cbook\u001b[38;5;241m.\u001b[39mnormalize_kwargs(kwargs, mlines\u001b[38;5;241m.\u001b[39mLine2D)\n\u001b[0;32m-> 1721\u001b[0m lines \u001b[38;5;241m=\u001b[39m [\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_lines(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, data\u001b[38;5;241m=\u001b[39mdata, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)]\n\u001b[1;32m   1722\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m line \u001b[38;5;129;01min\u001b[39;00m lines:\n\u001b[1;32m   1723\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39madd_line(line)\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/matplotlib/axes/_base.py:303\u001b[0m, in \u001b[0;36m_process_plot_var_args.__call__\u001b[0;34m(self, axes, data, *args, **kwargs)\u001b[0m\n\u001b[1;32m    301\u001b[0m     this \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m args[\u001b[38;5;241m0\u001b[39m],\n\u001b[1;32m    302\u001b[0m     args \u001b[38;5;241m=\u001b[39m args[\u001b[38;5;241m1\u001b[39m:]\n\u001b[0;32m--> 303\u001b[0m \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_plot_args\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    304\u001b[0m \u001b[43m    \u001b[49m\u001b[43maxes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mthis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mambiguous_fmt_datakey\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mambiguous_fmt_datakey\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/matplotlib/axes/_base.py:499\u001b[0m, in \u001b[0;36m_process_plot_var_args._plot_args\u001b[0;34m(self, axes, tup, kwargs, return_kwargs, ambiguous_fmt_datakey)\u001b[0m\n\u001b[1;32m    496\u001b[0m     axes\u001b[38;5;241m.\u001b[39myaxis\u001b[38;5;241m.\u001b[39mupdate_units(y)\n\u001b[1;32m    498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m x\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m!=\u001b[39m y\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]:\n\u001b[0;32m--> 499\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mx and y must have same first dimension, but \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    500\u001b[0m                      \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhave shapes \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mx\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m and \u001b[39m\u001b[38;5;132;01m{\u001b[39;00my\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    501\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m x\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m2\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m y\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m2\u001b[39m:\n\u001b[1;32m    502\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mx and y can be no greater than 2D, but have \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    503\u001b[0m                      \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mshapes \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mx\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m and \u001b[39m\u001b[38;5;132;01m{\u001b[39;00my\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mValueError\u001b[0m: x and y must have same first dimension, but have shapes (79,) and (80,)"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1500x700 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(15, 7))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(range(1, 80), train_losses, label='Train Loss') # change this number after '(1, _)' to num_epochs+1\n",
    "plt.plot(range(1, 80), test_losses, label='Test Loss') # change this number after '(1, _)' to num_epochs+1\n",
    "plt.plot(range(1, 80), val_losses, label='Validation Loss') # change this number after '(1, _)' to num_epochs+1\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Losses on GiMeFive') # change\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(range(1, 80), train_accuracies, label='Train Accuracy') # change this number after '(1, _)' to num_epochs+1\n",
    "plt.plot(range(1, 80), test_accuracies, label='Test Accuracy') # change this number after '(1, _)' to num_epochs+1\n",
    "plt.plot(range(1, 80), val_accuracies, label='Validation Accuracy') # change this number after '(1, _)' to num_epochs+1\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.title('Accuracies on GiMeFive') # change\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame({\n",
    "    'Epoch': range(1, 60), # change this number after '(1, _)' to num_epochs+1\n",
    "    'Train Loss': train_losses,\n",
    "    'Test Loss': test_losses,\n",
    "    'Validation Loss': val_losses,\n",
    "    'Train Accuracy': train_accuracies,\n",
    "    'Test Accuracy': test_accuracies,\n",
    "    'Validation Accuracy': val_accuracies\n",
    "})\n",
    "df.to_csv('result_gimefive.csv', index=False) # change this CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
